## New Generation of Application Securty Thinking

1. TDD with Code Coverage
2. Threat Models
3. Docker and Containers
4. Test Automation
5. SAST/DAST/IAST/WAF
6. Clever Fuzzing
7. JIRA Risk workflows
8. Kanban for Quality fixes
9. Web Services visualisation
10. ELK


## SAST/DAST/IAST/WAF

### SAST (Static)

- Probs with SAST Research
- The myth of the 'Big Red Button' (which all buyers want to buy and all vendors want to sell)
- The 'SAST Roadmap' that had key 'customer demands' like Oracle support (to and engine that was not really working ok)
 - The curse of the Customers who buys your product and changes your roadmap to add features they need (to make it 'Enterprise ready')
  - The customer is paying for feature XYZ
   - The devs are focused on non-critical stuff
   - Meanwhile the product doesn't really work (specially on security, and the claims made by the sales team (believed by the buyers)))
    - the fact that buyers believe that a product works, means that no further efforts will be placed in dealing with it (which means that the customer is still has the original problem)
    - Story of 'backup service' that was not really doing the backups (just buying insurance for the few cases where data was lost and they had to pay penalties for not having the data)
- The 'Big Red Button' can indeed be created:
 - But it needs to be an evolution (with lots of customizations)
 - For this to work, customization has to be a core features of the SAST engines (not as 'extra add-in')
  - The reason is that all apps/frameworks are custom and have custom logic
- The 'Big Red Button' is how CI workflows can scale
- Big paradigm shift for me: We need a SAST like engine just to analyze the complexity of normal business logic (for example the authorization rules of an CMS)

#### SAST strategy to scan methods/modules

  - all inputs as sources
  - all outputs as syncs  
  - glue results
  - (add diagram of how it works)

  - execute modules/methods individually to confirm understanding (or improve it)
  - use code coverage to understand coverage/understanding

#### Workflow of deleting all rules

  - creating a list of all methods used
  - add rules for only those methods
  - significantly

#### The radioactive pill

  - track data as it travels through the application

#### Workflow of making SQL methods sinks

  - not about SQL injection
  - detect Direct Object references attacks

#### Filtering millions of traces

  - sorting strings is fast (millions per second)
  - it is all a graph

#### Visualizing vulnerable paths

  - join traces (show diagram)
  - detect choke points
  - attack surface

#### Best asset of an SAST engine is the inner graphs

  - not the results
  - analogy of 'global census analysis' of 3 page report (from millions of data points)
  - all engines create an internal representation which is gold
  - specially if that internal representation is 'common across multiple languages'

#### Generating millions of traces

  - once we can filter traces, we want more
  - millions of pre-calculated traces allow the real-time visualization for a particular code location of: 'what data gets here?' and 'what happens from here?'
  - multi step analysis


### DAST

  - deliver much better results (since they have the exploit)
  - see real world
  - struggle to get coverage
  - very effective when feed traffic from e2e tests

### IAST

  - new kid on block (Contrast one of the best players)
  - lots of potential
  - need to look more into it

### WAF

- Case study: prob with commercial WAFS:
 - need to be used by devs and communicate with apps
 - in app firewalls have issue of polluting App Stack (and make it less resilient)
  - it is a nice when the firewall can be separated and have its own engine (and execution space)
